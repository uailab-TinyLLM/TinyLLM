# TinyLLM

### Models
| Model Name | Affiliation | Model Size | Release Date | Explanation | ðŸ”— Link |
| --- | --- | --- | --- | --- | --- |
| Bloom | BigScience | 560M | 2022.11 | A smaller-scale version of BLOOM. | [Link](https://huggingface.co/bigscience/bloom-560m) |
| Bloomz | BigScience | 560M | 2022.11 | A multilingual variant of BLOOM. | [Link](https://huggingface.co/bigscience/bloomz-560m) |
| Cerebras-GPT | Cerebras | 590M | 2023.03 | A larger-scale GPT model by Cerebras. | [Link](https://huggingface.co/cerebras/Cerebras-GPT-590M) |
| Cerebras-GPT | Cerebras | 256M | 2023.03 | A medium-scale GPT model by Cerebras. | [Link](https://huggingface.co/cerebras/Cerebras-GPT-256M) |
| Cerebras-GPT | Cerebras | 111M | 2023.03 | A small-scale GPT model by Cerebras. | [Link](https://huggingface.co/cerebras/Cerebras-GPT-111M) |
| Danube3 | H2O | 500M | 2024.07 | A medium-scale model by H2O.ai. | [Link](https://huggingface.co/h2oai/h2o-danube3-500m-base) |
| Flan-T5 | Google | Base | 2023.01 | A fine-tuned T5 model by Google. | [Link](https://huggingface.co/google/flan-t5-base) |
| Galactica | Meta | 125M | 2022.11 | A scientific language model for academic applications. | [Link](https://huggingface.co/facebook/galactica-125m) |
| LaMini-GPT | MBZUAI | 774M | 2023.04 | A larger-scale variant of LaMini-GPT. | [Link](https://huggingface.co/MBZUAI/LaMini-GPT-774M) |
| LaMini-GPT | MBZUAI | 124M | 2023.04 | A compact GPT model optimized for efficiency. | [Link](https://huggingface.co/MBZUAI/LaMini-GPT-124M) |
| LiteLlama | ahxt | 460M | N/A | A lightweight Llama-based model. | [Link](https://huggingface.co/ahxt/LiteLlama-460M-1T) |
| OPT | Meta | 350M | 2022.05 | A mid-sized version of the OPT model. | [Link](https://huggingface.co/facebook/opt-350m) |
| OPT | Meta | 125M | 2022.05 | A small-scale version of the OPT model. | [Link](https://huggingface.co/facebook/opt-125m) |
| Pythia | EleutherAI | 410M | 2023.03 | A larger-scale version in the Pythia series. | [Link](https://huggingface.co/EleutherAI/pythia-410m) |
| Pythia | EleutherAI | 160M | 2023.03 | A small-scale version of the Pythia series. | [Link](https://huggingface.co/EleutherAI/pythia-160m) |
| PhoneLM | mllmTeam | 0.5B | 2024.11 | A language model optimized for mobile applications. | [Link](https://huggingface.co/mllmTeam/PhoneLM-0.5B) |
| Qwen1.5 | Alibaba | 0.5B | 2024.02 | A Qwen series model optimized for efficiency. | [Link](https://huggingface.co/Qwen/Qwen1.5-0.5B) |
| Qwen2.5 | Alibaba | 0.5B | 2024.09 | The next iteration in the Qwen series. | [Link](https://huggingface.co/Qwen/Qwen2.5-0.5B) |
| SmolLM | Hugging Face | 360M | 2024.07 | A larger variant of SmolLM. | [Link](https://huggingface.co/HuggingFaceTB/SmolLM-360M) |
| SmolLM | Hugging Face | 135M | 2024.07 | A compact language model optimized for lightweight applications. | [Link](https://huggingface.co/HuggingFaceTB/SmolLM-135M) |
| TinyLlama | TinyLlama | 1.1B | 2023.12 | A compact Llama-based model. | [Link](https://huggingface.co/TinyLlama/TinyLlama_v1.1) |


### Evaluation Datasets

| Dataset Name | Explanation | ðŸ”— Link |
| --- | --- | --- |
| ARC | Science question dataset for QA.<br>- ARC-e : ARC-easy | [ai2_arc](https://huggingface.co/datasets/allenai/ai2_arc) |
| OBQA | a QA dataset modeled after open-book exams, designed to test multi-step reasoning, commonsense knowledge, and deep text comprehension. | [openbookqa](https://huggingface.co/datasets/allenai/openbookqa) |
| BoolQ | QA dataset for yes/no questions | [boolq](https://huggingface.co/datasets/google/boolq) |
| PIQA | QA dataset for physical commonsense reasoning and a corresponding | [piqa](https://huggingface.co/datasets/ybisk/piqa) |
| SIQA | question-answering,  designed to evaluate social commonsense reasoning about people's actions and their social implications. | [social_i_qa](https://huggingface.co/datasets/allenai/social_i_qa) |
| WinoGrande | fill-in-the-blank problems | [winogrande](https://huggingface.co/datasets/allenai/winogrande) |
| HellaSwag | Common sense natural language reasoning | [hellaswag](https://huggingface.co/datasets/Rowan/hellaswag) |
