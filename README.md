# TinyLLM

### Models
| Model Name | Explanation | ðŸ”— Link |
| --- | --- | --- |
|... | | |

### Evaluation Datasets

| Dataset Name | Explanation | ðŸ”— Link |
| --- | --- | --- |
| ARC | Science question dataset for QA.
ARC-e : ARC-easy
ARC-c: ARC-challenge | https://huggingface.co/datasets/allenai/ai2_arc |
| OBQA | a QA dataset modeled after open-book exams, designed to test multi-step reasoning, commonsense knowledge, and deep text comprehension. | https://huggingface.co/datasets/allenai/openbookqa |
| BoolQ | QA dataset for yes/no questions | https://huggingface.co/datasets/google/boolq |
| PIQA | QA dataset for physical commonsense reasoning and a corresponding | https://huggingface.co/datasets/ybisk/piqa |
| WinoGrande | fill-in-the-blank problems | https://huggingface.co/datasets/allenai/winogrande |
| HellaSwag | Common sense natural language reasoning | https://huggingface.co/datasets/Rowan/hellaswag |
| SIQA | question-answering,  designed to evaluate social commonsense reasoning about people's actions and their social implications. | https://huggingface.co/datasets/allenai/social_i_qa |
